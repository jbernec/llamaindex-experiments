{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9e82834-2dc6-4702-a25f-5794e7de14a8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### This notebook is mainly used to create the Azure AI Search index to be used by the Llama set of libraries for vector embedding, uploading the claims data chunks and search retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc213106-2f85-4540-9b86-cbb9beb2f5e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 1: Import required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b2e0768-aab8-4642-bf01-71be5b08041f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult, AnalyzeDocumentRequest, ContentFormat\n",
    "import time\n",
    "import azure.identity\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import get_bearer_token_provider\n",
    "from autogen import AssistantAgent, UserProxyAgent, register_function\n",
    "from typing_extensions import List, Annotated\n",
    "import autogen\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import SearchField, SearchFieldDataType, VectorSearch, SimpleField, SearchableField, HnswAlgorithmConfiguration, HnswParameters, VectorSearchAlgorithmMetric, ExhaustiveKnnAlgorithmConfiguration, ExhaustiveKnnParameters, VectorSearchProfile, AzureOpenAIVectorizer, AzureOpenAIParameters, SemanticConfiguration, SemanticSearch, SemanticPrioritizedFields, SemanticField, SearchIndex\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "from azure.search.documents.models import (\n",
    "    QueryType,\n",
    "    QueryCaptionType,\n",
    "    QueryAnswerType\n",
    ")\n",
    "from llama_parse import LlamaParse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3debcf4e-262a-4ceb-8273-6bff9948e04a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 2: Set credential variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b8b473b-62a8-4ca9-a2eb-0e1273057b92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code loads and sets the necessary variables for Azure services.\n",
    "The variables are loaded from Azure Key Vault.\n",
    "\"\"\"\n",
    "\n",
    "azure_openai_endpoint=dbutils.secrets.get(scope=\"myscope\", key=\"aoai-endpoint\")\n",
    "azure_openai_api_key=dbutils.secrets.get(scope=\"myscope\", key=\"aoai-api-key\")\n",
    "azure_openai_api_version = \"2024-02-15-preview\"\n",
    "azure_openai_embedding_deployment = dbutils.secrets.get(scope=\"myscope\", key=\"aoai-embedding-deployment\")\n",
    "doc_intelligence_endpoint = dbutils.secrets.get(scope=\"myscope\", key=\"docintelligence-endpoint\")\n",
    "doc_intelligence_key = dbutils.secrets.get(scope=\"myscope\", key=\"docintelligence-key\")\n",
    "search_credential = AzureKeyCredential(dbutils.secrets.get(scope=\"myscope\", key=\"aisearch-adminkey\"))\n",
    "search_endpoint = dbutils.secrets.get(scope=\"myscope\", key=\"aisearch-endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0970805a-ca60-4687-908c-832e3d252999",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 3: Connect to blob storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29f9fd4e-db33-4260-9d5e-507876264871",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Connect to Blob Storage\n",
    "blob_connection_string = dbutils.secrets.get(scope=\"myscope\", key=\"blobstore-connstr\")\n",
    "blob_container_name = \"insurance-rag\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "container_client = blob_service_client.get_container_client(blob_container_name)\n",
    "blobs = container_client.list_blobs()\n",
    "container_url = container_client.url\n",
    "print(container_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb8fac3c-867e-44b8-8cbb-5b1144ff8b62",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    parsing_instruction=\"This is an auto insurance claim document.\",\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name= \"openai-gpt-4o\",\n",
    "    vendor_multimodal_api_key= dbutils.secrets.get(scope=\"myscope\", key=\"aoai-api-key\"),\n",
    "    api_key = dbutils.secrets.get(scope=\"myscope\", key=\"llamacloudkey\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1608acb-d3e7-47e7-950a-212ac8cd4745",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dir(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66fdd514-333a-4c99-81b1-d36f22b3fb0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.readers.azstorage_blob import AzStorageBlobReader\n",
    "\n",
    "loader = AzStorageBlobReader(\n",
    "    container_name= blob_container_name,\n",
    "    connection_string=blob_connection_string\n",
    ")\n",
    "\n",
    "documents = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73c98fd6-04fd-43b3-a44a-60c09cb12267",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "help(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12802a5a-2f34-4511-be9c-5af1d3b8ec25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dir(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9020cc5c-a7ef-49c2-b308-4c24a1a078e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d736a00-cf5e-42cc-9160-0d5eca197014",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": dbutils.secrets.get(scope=\"myscope\", key=\"aoai-deploymentname\"),\n",
    "            \"api_key\": dbutils.secrets.get(scope=\"myscope\", key=\"aoai-api-key\"),\n",
    "            \"base_url\": dbutils.secrets.get(scope=\"myscope\", key=\"aoai-endpoint\"),\n",
    "            \"api_type\": \"azure\",\n",
    "            \"api_version\": \"2024-02-15-preview\",\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "gpt4_config = {\n",
    "    \"cache_seed\": 42,\n",
    "    \"temperature\": 0,\n",
    "    \"config_list\": llm_config[\"config_list\"],\n",
    "    \"timeout\": 120\n",
    "}\n",
    "\n",
    "\n",
    "ai_search_agent = AssistantAgent(\n",
    "    name=\"AISearchAssistant\",\n",
    "    system_message=\"You are a helpful AI agent.\"\n",
    "    \"You can help with Azure AI Search service.\"\n",
    "    \"Return TERMINATE when the task is done\",\n",
    "    llm_config=gpt4_config,\n",
    ")\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    is_termination_msg=lambda x: \"terminate\" in x.get(\"content\", \"\").lower()\n",
    "    if x.get(\"content\", \"\") is not None\n",
    "    else False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    code_execution_config=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e06881b-573a-456e-986f-e329e83cbc0c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 5: Define required function and tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c3c0ce6-fd82-4725-9fcf-1260c263c5e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@user_proxy.register_for_execution()\n",
    "@ai_search_agent.register_for_llm(\n",
    "    description=\"A tool or function for search retrieval from Azure AI Search\"\n",
    ")\n",
    "def search_retrieval(user_input:str) -> str:\n",
    "        \"\"\"\n",
    "        Search and retrieve answers from Azure AI Search.\n",
    "        Returns:\n",
    "            str\n",
    "        \"\"\"\n",
    "        query = user_input\n",
    "        search_client = SearchClient(endpoint=search_endpoint, index_name=index_name, credential=search_credential)\n",
    "        vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=5, fields=\"embedding\", exhaustive=True)\n",
    "\n",
    "        r = search_client.search(  \n",
    "        search_text=query,\n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"id\", \"chunk\"],\n",
    "        query_type=QueryType.SEMANTIC,\n",
    "        semantic_configuration_name='mySemanticConfig',\n",
    "        query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "        query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "        top=1\n",
    "    )\n",
    "        #query_result = results.get_answers()[0].text\n",
    "        results = [doc[\"content\"].replace(\"\\n\", \"\").replace(\"\\r\", \"\") for doc in r]\n",
    "        content = \"\\n\".join(results)\n",
    "        return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ca0b88a-1c99-4c67-8183-8fd073b118a8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 6: Create Azure AI Search Index and Vector Configurations to be used by the llama generated vectors and claims data chunks and agents for retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea172d55-824d-49f8-ab03-4584a6898afc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the search index fields and vector search configuration\n",
    "\n",
    "# Create a search index client required to create the index\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=search_credential)\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", key=True, type=SearchFieldDataType.String, filterable=True, sortable=True, facetable=True),\n",
    "    SearchableField(name=\"metadata\", type=SearchFieldDataType.String, filterable=True, searchable=True, retrievable=True),\n",
    "    SearchableField(name=\"chunk\", type=SearchFieldDataType.String, searchable=True, sortable=True, facetable=True, retrievable=True),\n",
    "    SearchableField(name=\"doc_id\", type=SearchFieldDataType.String, searchable=True, filterable=True, retrievable=True),\n",
    "    SearchField(name=\"embedding\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), searchable=True, retrievable=True, hidden=False, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\")\n",
    "]\n",
    "\n",
    "# Configure the vector search config\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\",\n",
    "            parameters=HnswParameters(\n",
    "                m=4,\n",
    "                ef_construction=400,\n",
    "                ef_search=500,\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer=\"myOpenAI\",  \n",
    "        ),\n",
    "    ],\n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            azure_open_ai_parameters=AzureOpenAIParameters(  \n",
    "                resource_uri=azure_openai_endpoint,  \n",
    "                deployment_id=azure_openai_embedding_deployment,  \n",
    "                api_key=azure_openai_api_key,  \n",
    "            ),  \n",
    "        ),  \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Configure semantic search on the index\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"mySemanticConfig\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        content_fields=[\n",
    "            SemanticField(field_name=\"chunk\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "# Create the semantic search config\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index\n",
    "index_name = \"llama-insurance-index\"\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)\n",
    "result = index_client.create_or_update_index(index=index)\n",
    "print(f\"{result.name} created\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "llama-azblobstorage-lab",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
